p8105_hw2_zl2746
================
Ze Li
2023-09-27

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.3     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.3     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readr)
library(readxl)
```

## Problem 1

### Step 1.

Use `separate()` to break up the variable `mon` into integer variables
`year`, `month`, and `day`;

replace month number with month name;

create a `president` variable taking values `gop` and `dem`, and remove
`prez_dem` and `prez_gop`;

and remove the `day` variable.

``` r
month_df = 
  read_csv("fivethirtyeight_datasets/pols-month.csv") |>
  janitor::clean_names()
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
month_sep_df =
  separate(month_df,col=mon,c("year","month","day"),sep="-") |>
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    day = as.integer(day),
    month = month(month, label = TRUE),
    #month_full = month(month, label = TRUE, abbr = FALSE)
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")
  ) |>
  select(-starts_with("day"))
```

### Step 2.

Clean the data in snp.csv using a similar process to the above.

For consistency across datasets, arrange according to year and month,
and organize so that year and month are the leading columns.

``` r
snp_df = 
  read_csv("fivethirtyeight_datasets/snp.csv") |>
  janitor::clean_names()
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
snp_sep_df =
  separate(snp_df,col=date,c("month","day","year"), sep="/") |>
  mutate(
    month = as.integer(month),
    day = as.integer(day),
    year = as.integer(year),
    month = month(month, label = TRUE),
    year = ifelse(year<16, year+2000, year+1900)
  ) |>
  select(-starts_with("day")) |>
  relocate(year)
```

### Step 3.

Tidy the unemployment data so that it can be merged with the previous
datasets.

This process will involve switching from “wide” to “long” format;
ensuring that key variables have the same name;

and ensuring that key variables take the same values.

``` r
unem_df = 
  read_csv("fivethirtyeight_datasets/unemployment.csv") |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month",
    values_to = "unemployment"
  ) |> 
  rename(year = Year) |> 
  select(year, month, unemployment) #|>
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

### Step 4.

Join the datasets by merging snp into pols, and merging unemployment
into the result.

``` r
cdata_p1 = 
  left_join(month_sep_df, snp_sep_df) |>
  left_join(x = _, y = unem_df) 
```

    ## Joining with `by = join_by(year, month)`
    ## Joining with `by = join_by(year, month)`

### Step 5.

Write a short paragraph about these datasets. Explain briefly what each
dataset contained, and describe the resulting dataset (e.g. give the
dimension, range of years, and names of key variables).

The `pol_month` data has 822 observations and 11 variables and tells us
about the party affiliation distribution (democrat or republican) for
governors and senators for a given year from years 1947 to 2015. It also
tells us whether the sitting president was a democrat or republican.

The `snp` data has 787 observations and 3 variables, ranging from years
1950 to 2015.

The `unemployment` data has 816 observations and 3 variables ranging
from years 1948 to 2015. In Januarys in or after 1975 in which a
democrat was president, the **average unemployment rate was 6.57**.

The average unemployment rate over the same time period in which a
republican was president was 6.47.

## Problem 2

``` r
Mr.Trash_df = 
  read_excel("202309 Trash Wheel Collection Data.xlsx",sheet = 1, range = "A2:N586") |>
  janitor::clean_names() |>
  mutate(
    homes_powered = (weight_tons*500)/30
  ) |>
  drop_na(dumpster) |>
  add_column(type = "Mr. Trash")

Prof.Trash_df = 
  read_excel("202309 Trash Wheel Collection Data.xlsx",sheet = 2) |>
  janitor::clean_names() |>
  mutate(
    homes_powered = (weight_tons*500)/30,
    year = as.character(year)
  ) |>
  drop_na(dumpster) |>
  add_column(type = "Professor Trash") 

G.Trash_df = 
  read_excel("202309 Trash Wheel Collection Data.xlsx",sheet = 4) |>
  janitor::clean_names() |>
  mutate(
    homes_powered = (weight_tons*500)/30,
    year = as.character(year)
  ) |>
  drop_na(dumpster) |>
  add_column(type = "Gwynnda Trash")

cdata_p2 = 
  bind_rows(Mr.Trash_df, Prof.Trash_df) |>
  bind_rows(x = _, y = G.Trash_df)
```

Write a paragraph about these data; you are encouraged to use inline R.
Be sure to note the number of observations in the resulting dataset, and
give examples of key variables.

The `Mr.Trash` data has 584 observations and 15 variables and tells us
about the information on the dumpter number, date of collection, amount
of total litter and litter type. By the `home powered note`, the
`homes_powered` is calculated using trash `weight_tons`. On 2014-05-16,
dumpster 1 has 4.31 tons of trash, which could power average 71.8333333
homes powered.

The `Prof.Trash` data has 106 observations and 14 variables and tells us
about the information on the dumpter number, date of collection, amount
of total litter and litter type. On 2017-01-02, dumpster 1 has 1.79 tons
of trash, which could power average 29.8333333 homes powered.

The `G.Trash` data has 155 observations and 13 variables and tells us
about the information on the dumpter number, date of collection, amount
of total litter and litter type. On 2021-07-03, dumpster 1 has 0.93 tons
of trash, which could power average 15.5 homes powered.

The combined data `cdata_p2` has 845 observations and 15 variables.

For available data, what was the total weight of trash collected by
Professor Trash Wheel?

The total weight of trash collected by Professor Trash Wheel is 216.26
tons.

What was the total number of cigarette butts collected by Gwynnda in
July of 2021?

The total number of cigarette butts collected by Gwynnda in July of 2021
is 1.63^{4}.

## Problem 3

### Step 1.

Import, clean, and tidy the dataset of baseline demographics.

Ensure that sex and APOE4 carrier status are appropriate encoded
(i.e. not numeric), and remove any participants who do not meet the
stated inclusion criteria (i.e. no MCI at baseline).

``` r
base_df = 
  read_csv("data_mci/MCI_baseline.csv", skip = 1) |>
  janitor::clean_names() |>
  mutate(
    sex = recode(sex, "0" = "female", "1" = "male"),
    apoe4 = recode(apoe4, "0" = "non-apoe4 carrier", "1" = "apoe4 carrier"),
    age_at_onset = ifelse(age_at_onset == '.', NA, age_at_onset)
  ) 
```

    ## Rows: 483 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): Age at onset
    ## dbl (5): ID, Current Age, Sex, Education, apoe4
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
base_mci_df =
  base_df |>
  filter(current_age < age_at_onset | is.na(age_at_onset)) 
```

Discuss important steps in the import process and relevant features of
the dataset.

Because the first line is the description about each column variables,
skipped the first line when importing csv dataset. In addition, changed
sex and apoe4 from numeric into charater type. The most important step
to filter any participants who do not meet the stated inclusion
criteria.

The `base_df` data is the total recruited dataset, having 483
observations and 6 variables and tells us about id, current_age, sex,
education, apoe4, age_at_onset.

The `base_mci_df` data has 479 observations and 6 variables and tells us
about similar information with `base_df` but about people who has no MCI
at baseline.

There are 483 were recruited, and of 479 these develop MCI.

The average baseline age is 65.0467909.

30% proportion of women in the study are APOE4 carriers.

### Step 2.

Similarly, import, clean, and tidy the dataset of longitudinally
observed biomarker values;

``` r
amyloid = read_csv("data_mci/mci_amyloid.csv", skip = 1) |>
  janitor::clean_names() |>
  rename(
    id = study_id,
    time_0 = baseline
    ) |>
  pivot_longer(
    time_0:time_8, 
    names_to = "timeperiod",
    values_to = "time in years elapsed"
  ) 
```

    ## Rows: 487 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (5): Baseline, Time 2, Time 4, Time 6, Time 8
    ## dbl (1): Study ID
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Comment on the steps on the import process and the features of the
dataset.

Similarly, skipped the first line description to import csv data.
Furthermore, switching from “wide” to “long” format for 5 types of time
period and time (in years) elapsed since the study baseline to the visit
where biomarker Amyloid \_ 42/40 ratio was measured.

``` r
diffdata1 =
  anti_join(base_df, amyloid)
```

    ## Joining with `by = join_by(id)`

``` r
diffdata2 =
  anti_join(amyloid, base_df)
```

    ## Joining with `by = join_by(id)`

``` r
cdata_p3 = 
  inner_join(base_df, amyloid)
```

    ## Joining with `by = join_by(id)`

Matching `baseline` data with `amyloid` data, there are 8 data appear in
only the baseline.

Matching `amyloid` data with `baseline` data, there are 60 data appear
in only the amyloid.

The combined dataset has 2375 observations and 8 variables and tells us
about information about id, current_age, sex, education, apoe4,
age_at_onset, timeperiod, time in years elapsed.
